{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71831c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy transformers pathlib pandas gdown lxml hf_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d75357",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown --folder \"https://drive.google.com/drive/folders/1wAS0umYohuR53r4sqroxxiG2ab5p5msn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "babdc7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec81c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36cae02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rows = 13,711, Max sequence length = 1024\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "data_path = './Data/'\n",
    "df = pd.read_csv(data_path + 'test.csv')\n",
    "\n",
    "# 데이터 최대 길이 확인\n",
    "max_seq_len = df[\"seq\"].str.len().max()\n",
    "print(f\"✅ Rows = {len(df):,}, Max sequence length = {max_seq_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd218e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "MODEL_ID = \"InstaDeepAI/nucleotide-transformer-v2-100m-multi-species\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "model = AutoModelForMaskedLM.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "model = model.to(DEVICE).eval()\n",
    "\n",
    "MODEL_CAP = tokenizer.model_max_length \n",
    "EFFECTIVE_MAX_LEN = min(MODEL_CAP, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baa62888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 1024\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_CAP, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2c1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EsmForMaskedLM(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(4107, 512, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (position_embeddings): Embedding(2050, 512, padding_idx=1)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-21): 22 x EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            (activation_fn): SiLU()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (contact_head): EsmContactPredictionHead(\n",
       "      (regression): Linear(in_features=352, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): EsmLMHead(\n",
       "    (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=512, out_features=4107, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc4e96be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EsmTokenizer(name_or_path='InstaDeepAI/nucleotide-transformer-v2-100m-multi-species', vocab_size=4107, model_max_length=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '<unk>', 'pad_token': '<pad>', 'cls_token': '<cls>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<cls>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8434f5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EFFECTIVE_MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8665917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.ids  = df[\"ID\"].tolist()\n",
    "        self.seqs = df[\"seq\"].tolist()\n",
    "        self.tok  = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"ID\": self.ids[idx], \"seq\": self.seqs[idx]}\n",
    "\n",
    "def collate_fn(batch, tok=tokenizer, max_len=EFFECTIVE_MAX_LEN):\n",
    "    ids  = [b[\"ID\"] for b in batch]\n",
    "    seqs = [b[\"seq\"] for b in batch]\n",
    "    enc  = tok.batch_encode_plus(\n",
    "        seqs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\",          \n",
    "        truncation=True,\n",
    "        max_length=max_len\n",
    "    )\n",
    "    # attention_mask: pad 토큰이 0\n",
    "    return {\n",
    "        \"ids\": ids,\n",
    "        \"input_ids\": enc[\"input_ids\"],\n",
    "        \"attention_mask\": enc[\"attention_mask\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331abe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SeqDataset(df, tokenizer, EFFECTIVE_MAX_LEN)\n",
    "loader  = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                     num_workers=NUM_WORKERS, collate_fn=collate_fn)\n",
    "print(\"✅ Dataloader ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = []\n",
    "all_embs = []\n",
    "use_amp = (DEVICE == \"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attn_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=use_amp):\n",
    "            outs = model(\n",
    "                input_ids,\n",
    "                attention_mask=attn_mask,\n",
    "                encoder_attention_mask=attn_mask,   \n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "            # 마지막 히든스테이트: (B, L, H)\n",
    "            last_hidden = outs.hidden_states[-1]    # torch.Tensor\n",
    "\n",
    "            # mask 모양 맞추기: (B, L, 1)\n",
    "            mask_exp = attn_mask.unsqueeze(-1)      # 1 for valid tokens\n",
    "\n",
    "            # 패딩 제외 평균: sum(hidden * mask) / sum(mask)\n",
    "            summed = (last_hidden * mask_exp).sum(dim=1)                    # (B, H)\n",
    "            counts = mask_exp.sum(dim=1).clamp(min=1)                       # (B, 1)\n",
    "            seq_emb = summed / counts                                       # (B, H)\n",
    "\n",
    "        all_ids.extend(batch[\"ids\"])\n",
    "        all_embs.append(seq_emb.detach().cpu())\n",
    "\n",
    "emb = torch.vstack(all_embs).float()        # (N, H)\n",
    "N, H = emb.shape\n",
    "print(f\"✅ Embedding shape = {N} x {H}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(data_path + 'sample_submission.csv')\n",
    "\n",
    "emb_np = emb.numpy()\n",
    "emb_cols = [f\"emb_{i:04d}\" for i in range(emb_np.shape[1])]\n",
    "emb_df = pd.DataFrame(emb_np, columns=emb_cols)\n",
    "\n",
    "submission = pd.concat([sample_submission['ID'], emb_df], axis=1)\n",
    "submission.to_csv('baseline_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mol_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
